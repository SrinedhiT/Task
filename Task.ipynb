{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"C:\\\\Users\\\\Lampe\\\\Desktop\\\\sentiment analysis\\\\dataset\\\\dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'Windows-1252', 'confidence': 0.7290615013529563, 'language': ''}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chardet\n",
    "with open(dataset, 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(dataset,encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O\n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lampe\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Basic visualization of the data\n",
    "sns.countplot(data['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Punctuation\n",
    "punc = string.punctuation\n",
    "plist = punc\n",
    "def rempunc(text):\n",
    "    trans = str.maketrans('', '', plist)\n",
    "    return text.translate(trans)\n",
    "data['SentimentText']= data['SentimentText'].apply(lambda x: rempunc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 730 O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Omgaga Im sooo  im gunna CRy Ive be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me       TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99996</td>\n",
       "      <td>0</td>\n",
       "      <td>Cupcake  seems like a repeating problem   hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>cupcake arrrr we both replied to each other ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99998</td>\n",
       "      <td>0</td>\n",
       "      <td>CuPcAkE2120 ya i thought so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>CupcakeDollie Yes Yes Im glad you had more fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>cupcakekayla haha yes you do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment                                      SentimentText\n",
       "0           1          0                        is so sad for my APL friend\n",
       "1           2          0                      I missed the New Moon trailer\n",
       "2           3          1                              omg its already 730 O\n",
       "3           4          0             Omgaga Im sooo  im gunna CRy Ive be...\n",
       "4           5          0           i think mi bf is cheating on me       TT\n",
       "...       ...        ...                                                ...\n",
       "99984   99996          0  Cupcake  seems like a repeating problem   hope...\n",
       "99985   99997          1  cupcake arrrr we both replied to each other ov...\n",
       "99986   99998          0                       CuPcAkE2120 ya i thought so \n",
       "99987   99999          1  CupcakeDollie Yes Yes Im glad you had more fun...\n",
       "99988  100000          1                      cupcakekayla haha yes you do \n",
       "\n",
       "[99989 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Hashtags and Mentions\n",
    "def removemenandhash(text):\n",
    "    items = ['@','#']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in items :\n",
    "            text = text.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in items:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)\n",
    "data['SentimentText']= data['SentimentText'].apply(lambda x: removemenandhash(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 730 O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Omgaga Im sooo im gunna CRy Ive been at this d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99996</td>\n",
       "      <td>0</td>\n",
       "      <td>Cupcake seems like a repeating problem hope yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>cupcake arrrr we both replied to each other ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99998</td>\n",
       "      <td>0</td>\n",
       "      <td>CuPcAkE2120 ya i thought so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>CupcakeDollie Yes Yes Im glad you had more fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>cupcakekayla haha yes you do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment                                      SentimentText\n",
       "0           1          0                        is so sad for my APL friend\n",
       "1           2          0                      I missed the New Moon trailer\n",
       "2           3          1                              omg its already 730 O\n",
       "3           4          0  Omgaga Im sooo im gunna CRy Ive been at this d...\n",
       "4           5          0                 i think mi bf is cheating on me TT\n",
       "...       ...        ...                                                ...\n",
       "99984   99996          0  Cupcake seems like a repeating problem hope yo...\n",
       "99985   99997          1  cupcake arrrr we both replied to each other ov...\n",
       "99986   99998          0                        CuPcAkE2120 ya i thought so\n",
       "99987   99999          1  CupcakeDollie Yes Yes Im glad you had more fun...\n",
       "99988  100000          1                       cupcakekayla haha yes you do\n",
       "\n",
       "[99989 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ItemID  Sentiment                     SentimentText\n",
      "9      10          1  hmmmm i wonder how she my number\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 730 O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Omgaga Im sooo im gunna CRy Ive been at this d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99996</td>\n",
       "      <td>0</td>\n",
       "      <td>Cupcake seems like a repeating problem hope yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>cupcake arrrr we both replied to each other ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99998</td>\n",
       "      <td>0</td>\n",
       "      <td>CuPcAkE2120 ya i thought so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>CupcakeDollie Yes Yes Im glad you had more fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>cupcakekayla haha yes you do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment                                      SentimentText\n",
       "0           1          0                        is so sad for my APL friend\n",
       "1           2          0                      I missed the New Moon trailer\n",
       "2           3          1                              omg its already 730 O\n",
       "3           4          0  Omgaga Im sooo im gunna CRy Ive been at this d...\n",
       "4           5          0                 i think mi bf is cheating on me TT\n",
       "...       ...        ...                                                ...\n",
       "99984   99996          0  Cupcake seems like a repeating problem hope yo...\n",
       "99985   99997          1  cupcake arrrr we both replied to each other ov...\n",
       "99986   99998          0                        CuPcAkE2120 ya i thought so\n",
       "99987   99999          1  CupcakeDollie Yes Yes Im glad you had more fun...\n",
       "99988  100000          1                       cupcakekayla haha yes you do\n",
       "\n",
       "[99989 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lampe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords and doing the other necessary preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "  \n",
    "VERB_CODES = {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}\n",
    "\n",
    "def prep(text):\n",
    "  text = text.lower()\n",
    "  temp_sent =[]\n",
    "  words = nltk.word_tokenize(text)\n",
    "  tags = nltk.pos_tag(words)\n",
    "  for i, word in enumerate(words):\n",
    "      if tags[i][1] in VERB_CODES: \n",
    "          lemmatized = lemmatizer.lemmatize(word, 'v')\n",
    "      else:\n",
    "          lemmatized = lemmatizer.lemmatize(word)\n",
    "      if lemmatized not in stop_words and lemmatized.isalpha():\n",
    "          temp_sent.append(lemmatized)\n",
    "          \n",
    "  finalsent = ' '.join(temp_sent)\n",
    "  finalsent = finalsent.replace(\"n't\", \" not\")\n",
    "  finalsent = finalsent.replace(\"'m\", \" am\")\n",
    "  finalsent = finalsent.replace(\"'s\", \" is\")\n",
    "  finalsent = finalsent.replace(\"'re\", \" are\")\n",
    "  finalsent = finalsent.replace(\"'ll\", \" will\")\n",
    "  finalsent = finalsent.replace(\"'ve\", \" have\")\n",
    "  finalsent = finalsent.replace(\"'d\", \" would\")\n",
    "  return finalsent\n",
    "\n",
    "data['SentimentText']= data['SentimentText'].apply(lambda x: prep(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing links and numbers\n",
    "data['SentimentText'] = data['SentimentText'].str.strip().str.replace('   ', ' ').str.replace('  ', ' ')\n",
    "data['SentimentText'] = data['SentimentText'].str.replace('\\d+', '')\n",
    "data['SentimentText'] = data['SentimentText'].str.replace(r'http?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sad apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>miss new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>omgaga im sooo im gunna cry ive dentist since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>think mi bf cheat tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99996</td>\n",
       "      <td>0</td>\n",
       "      <td>cupcake seem like repeating problem hope youre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>cupcake arrrr reply different tweet time ill s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99998</td>\n",
       "      <td>0</td>\n",
       "      <td>ya think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>cupcakedollie yes yes im glad fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>cupcakekayla haha yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment                                      SentimentText\n",
       "0           1          0                                     sad apl friend\n",
       "1           2          0                              miss new moon trailer\n",
       "2           3          1                                        omg already\n",
       "3           4          0  omgaga im sooo im gunna cry ive dentist since ...\n",
       "4           5          0                               think mi bf cheat tt\n",
       "...       ...        ...                                                ...\n",
       "99984   99996          0  cupcake seem like repeating problem hope youre...\n",
       "99985   99997          1  cupcake arrrr reply different tweet time ill s...\n",
       "99986   99998          0                                           ya think\n",
       "99987   99999          1                  cupcakedollie yes yes im glad fun\n",
       "99988  100000          1                              cupcakekayla haha yes\n",
       "\n",
       "[99989 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word',min_df=0, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.fit_transform(data['SentimentText'])\n",
    "Y = data.iloc[:,[1]].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<99989x98734 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 644819 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lampe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Multinomial Naive Bayes with TF-IDF vectorizer\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Naive Bayes Model using TF-IDF vectorizer is :  0.7214054738807214\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for Naive Bayes Model using TF-IDF vectorizer is : \", accuracy_score(Y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Naive Bayes Model using TF-IDF vectorizer : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.53      0.62     13092\n",
      "           1       0.70      0.87      0.78     16905\n",
      "\n",
      "    accuracy                           0.72     29997\n",
      "   macro avg       0.73      0.70      0.70     29997\n",
      "weighted avg       0.73      0.72      0.71     29997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification Report for Naive Bayes Model using TF-IDF vectorizer : \\n\\n\", classification_report(Y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "x = count.fit_transform(data['SentimentText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,[1]].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lampe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Multinomial Naive Bayes with CountVectorizer\n",
    "m1 = MultinomialNB()\n",
    "m1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2pred = m1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Naive Bayes Model using CountVectorizer is :  0.7428742874287428\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for Naive Bayes Model using CountVectorizer is : \", accuracy_score(y_test, y2pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Naive Bayes model using CountVectorizer : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70     13092\n",
      "           1       0.77      0.78      0.77     16905\n",
      "\n",
      "    accuracy                           0.74     29997\n",
      "   macro avg       0.74      0.74      0.74     29997\n",
      "weighted avg       0.74      0.74      0.74     29997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Naive Bayes model using CountVectorizer : \\n\\n\", classification_report(y_test, y2pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lampe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Logistic Regression Model (using TF-IDF vectorizer) is :  0.746941360802747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lampe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Using Logistic Regression with TF-IDF vectorizer\n",
    "lrm1 = LogisticRegression(solver='lbfgs')\n",
    "lrm1.fit(X_train, Y_train)\n",
    "lr1pred = lrm1.predict(X_test)\n",
    "print(\"Accuracy Score for Logistic Regression Model (using TF-IDF vectorizer) is : \", accuracy_score(Y_test, lr1pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression Model using TF-IDF vectorizer : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.68     13092\n",
      "           1       0.74      0.84      0.79     16905\n",
      "\n",
      "    accuracy                           0.75     29997\n",
      "   macro avg       0.75      0.73      0.74     29997\n",
      "weighted avg       0.75      0.75      0.74     29997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Logistic Regression Model using TF-IDF vectorizer : \\n\\n\", classification_report(Y_test, lr1pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lampe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\Lampe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Logistic Regression with CountVectorizer\n",
    "LR_model = LogisticRegression(solver='lbfgs')\n",
    "LR_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Logistic Regression Model (using CountVectorizer) is :  0.7502416908357502\n"
     ]
    }
   ],
   "source": [
    "lrpred = LR_model.predict(x_test)\n",
    "print(\"Accuracy Score for Logistic Regression Model (using CountVectorizer) is : \", accuracy_score(y_test, lrpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression Model using CountVectorizer : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70     13092\n",
      "           1       0.76      0.82      0.79     16905\n",
      "\n",
      "    accuracy                           0.75     29997\n",
      "   macro avg       0.75      0.74      0.74     29997\n",
      "weighted avg       0.75      0.75      0.75     29997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Logistic Regression Model using CountVectorizer : \\n\\n\", classification_report(y_test, lrpred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
